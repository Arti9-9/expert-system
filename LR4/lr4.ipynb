{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16b4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import *\n",
    "from nltk import word_tokenize\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792d4a4",
   "metadata": {},
   "source": [
    "## Выгрузка данных из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae07ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.os.ms-windows.misc', 'comp.sys.mac.hardware', 'sci.space']\n",
    "remove = ['headers', 'footers', 'quotes']\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories, remove=remove)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, categories=categories, remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924c81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = pd.DataFrame(twenty_train, columns=['data', 'target']).replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True)\n",
    "twenty_test = pd.DataFrame(twenty_test, columns=['data', 'target']).replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3233496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    nltk_tokens = word_tokenize(data)\n",
    "    line = ''\n",
    "    for word in nltk_tokens:\n",
    "        line += ' ' + porter_stemmer.stem(word)\n",
    "    return line\n",
    "\n",
    "twenty_train.insert(loc=1, column='data_stemmed', value=twenty_train['data'].apply(lambda text: stemming(text)))\n",
    "twenty_test.insert(loc=1, column='data_stemmed', value=twenty_test['data'].apply(lambda text: stemming(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a78c74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings \n",
    "from sklearn.exceptions import FitFailedWarning, ConvergenceWarning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fe78d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to 0.0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    'KNeighborsClassifier': {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__n_neighbors': (1, 3, 5, 10),\n",
    "        'clf__p': (1, 2)\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__criterion': ('gini', 'entropy'),\n",
    "        'clf__max_depth': [*range(1,5,1), *range(5,101,20)]\n",
    "    },\n",
    "    'LinearSVC': [{\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__loss': ['squared_hinge'],\n",
    "        'clf__penalty': ('l1', 'l2')\n",
    "    },\n",
    "        {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__loss': ['hinge'],\n",
    "        'clf__penalty': ['l2']\n",
    "    }],\n",
    "}\n",
    "\n",
    "gs = {}\n",
    "for clf, param in parameters.items():\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', eval(clf)())\n",
    "    ])\n",
    "    gs[clf] = GridSearchCV(text_clf, param, n_jobs=-1, error_score=0.0)\n",
    "    gs[clf].fit(X = twenty_train['data'], y = twenty_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca430db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "comp.os.ms-windows.misc       0.64      0.37      0.46       394\n",
      "  comp.sys.mac.hardware       0.61      0.28      0.38       385\n",
      "              sci.space       0.44      0.86      0.58       394\n",
      "\n",
      "               accuracy                           0.50      1173\n",
      "              macro avg       0.56      0.50      0.48      1173\n",
      "           weighted avg       0.56      0.50      0.48      1173\n",
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "comp.os.ms-windows.misc       0.83      0.68      0.75       394\n",
      "  comp.sys.mac.hardware       0.80      0.66      0.72       385\n",
      "              sci.space       0.66      0.90      0.77       394\n",
      "\n",
      "               accuracy                           0.75      1173\n",
      "              macro avg       0.77      0.75      0.75      1173\n",
      "           weighted avg       0.77      0.75      0.75      1173\n",
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "comp.os.ms-windows.misc       0.89      0.78      0.83       394\n",
      "  comp.sys.mac.hardware       0.87      0.82      0.84       385\n",
      "              sci.space       0.79      0.93      0.86       394\n",
      "\n",
      "               accuracy                           0.84      1173\n",
      "              macro avg       0.85      0.84      0.84      1173\n",
      "           weighted avg       0.85      0.84      0.84      1173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf, param in parameters.items():\n",
    "    predicted = gs[clf].predict(twenty_test['data'])\n",
    "    print(metrics.classification_report(twenty_test.target, predicted, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c2b3f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "r = {}\n",
    "def highlight_max(x, color):\n",
    "\n",
    "    return np.where(x == np.nanmax(x.to_numpy()), f\"color: {color};\", None)\n",
    "\n",
    "total_style = pd.Series(\"font-weight: bold;\", index=[1])\n",
    "\n",
    "for clf, param in parameters.items():\n",
    "    predicted = gs[clf].predict(twenty_test['data'])\n",
    "    \n",
    "    pd.DataFrame(gs[clf].cv_results_).to_excel('all' + clf + '.xlsx')\n",
    "    pd.DataFrame(classification_report(predicted, twenty_test.target, output_dict=True)).to_excel('best' + clf + '.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339715b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a9df05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
